{"cells":[{"cell_type":"markdown","metadata":{"id":"O1criSeL1Zpg"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKShqcNgdbLu"},"outputs":[],"source":["import argparse\n","import os\n","import sys\n","import logging\n","import pickle\n","from functools import partial\n","import time\n","from tqdm import tqdm\n","from collections import Counter\n","import random\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":86189,"status":"ok","timestamp":1723565310780,"user":{"displayName":"Phuong Dam","userId":"01072403895711103873"},"user_tz":-420},"id":"9UdyGuPF2LZb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81d1ff63-3023-4e63-912d-be9bd6f2ce60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.1+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.5)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (71.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->pytorch_lightning)\n","  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n","Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n","Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.11.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.4.0 torchmetrics-1.4.1\n"]}],"source":["pip install pytorch_lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Q92xt1yeSGU"},"outputs":[],"source":["import pytorch_lightning as pl\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks.progress import TQDMProgressBar\n","from pytorch_lightning.callbacks import LearningRateMonitor\n","\n","from transformers import AdamW, T5Tokenizer\n","from transformers import get_linear_schedule_with_warmup"]},{"cell_type":"code","source":["import transformers"],"metadata":{"id":"wBPr6DpqfrIC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pl.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"R1Eu9hK4fX1_","executionInfo":{"status":"ok","timestamp":1723565319642,"user_tz":-420,"elapsed":392,"user":{"displayName":"Phuong Dam","userId":"01072403895711103873"}},"outputId":"4f47f0b2-3d04-4e47-bafd-142ab86e3b9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.4.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["transformers.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"f3DpuFfkfm_-","executionInfo":{"status":"ok","timestamp":1723565322848,"user_tz":-420,"elapsed":10,"user":{"displayName":"Phuong Dam","userId":"01072403895711103873"}},"outputId":"dbaf16e1-ded1-46cb-9a7c-1509cb4f96ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'4.42.4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfIa6_34fgUT"},"outputs":[],"source":["# !pip install --upgrade transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6LZD72U-uJkA"},"outputs":[],"source":["# !pip uninstall -y transformers\n","# !pip install git+https://github.com/huggingface/transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20476,"status":"ok","timestamp":1723564103979,"user":{"displayName":"Phuong Dam","userId":"01072403895711103873"},"user_tz":-420},"id":"XnQbxtnOdg1L","outputId":"99541c27-a58c-4589-d656-800d3f9b8ecd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1306,"status":"ok","timestamp":1723564105276,"user":{"displayName":"Phuong Dam","userId":"01072403895711103873"},"user_tz":-420},"id":"4iaDjtjue79K","outputId":"c77d5859-3990-4108-8425-f205c599b8da"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Study/Capstone_Project/Aspect_based/multi-view-prompting-main-copy/src\n"]}],"source":["%cd /content/drive/MyDrive/Study/Capstone_Project/Aspect_based/multi-view-prompting-main-copy/src/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u15oUpTJdqO9"},"outputs":[],"source":["from t5 import MyT5ForConditionalGeneration\n","from data_utils import ABSADataset, task_data_list, cal_entropy\n","from const import *\n","from data_utils import read_line_examples_from_file\n","from eval_utils import compute_scores, extract_spans_para"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67tuN1nM8H5w"},"outputs":[],"source":["# from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# # Specify the model name you want to download\n","# model_name = \"t5-base\"  # Example: t5-small, t5-base, t5-large\n","\n","# # Load the tokenizer and model\n","# tokenizer = T5Tokenizer.from_pretrained(model_name)\n","# model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","# # Save the tokenizer and model to a directory\n","# save_directory = \"outputs/temp/final\"\n","\n","# tokenizer.save_pretrained(save_directory)\n","# model.save_pretrained(save_directory)\n","\n","# print(f\"Model and tokenizer saved to {save_directory}\")\n"]},{"cell_type":"markdown","metadata":{"id":"rMAoQxrY1dva"},"source":["# Method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNaUdRzFe6D_"},"outputs":[],"source":["def set_seed(seed: int = 42) -> None:\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    # torch\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    print(f\"Random seed set as {seed}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwtBr0ISqBqD"},"outputs":[],"source":["def init_args():\n","    parser = argparse.ArgumentParser()\n","    # basic settings\n","    parser.add_argument(\"--data_path\", default=\"../data/\", type=str)\n","    parser.add_argument(\n","                        \"--task\",\n","                        default='asqp',\n","                        choices=[\"asqp\", \"acos\", \"aste\", \"tasd\", \"unified\", \"unified3\"],\n","                        type=str,\n","                        help=\"The name of the task, selected from: [asqp, tasd, aste]\"\n","                        )\n","    parser.add_argument(\n","                        \"--dataset\",\n","                        default='gaming',\n","                        type=str,\n","                        help=\"The name of the dataset, selected from: [gaming]\")\n","    parser.add_argument(\n","                        \"--eval_data_split\",\n","                        default='test',\n","                        choices=[\"test\", \"dev\"],\n","                        type=str,\n","                        )\n","    parser.add_argument(\"--model_name_or_path\",\n","                        default='t5-base',\n","                        type=str,\n","                        help=\"Path to pre-trained model or shortcut name\"\n","                        )\n","    parser.add_argument(\"--output_dir\",\n","                        default='outputs/temp',\n","                        type=str,\n","                        help=\"Output directory\"\n","                        )\n","    parser.add_argument(\"--load_ckpt_name\",\n","                        default=None,\n","                        type=str,\n","                        help=\"load ckpt path\"\n","                        )\n","    parser.add_argument(\"--do_train\",\n","                        # default=True,\n","                        action='store_true',\n","                        help=\"Whether to run training.\"\n","                        )\n","    parser.add_argument(\n","                        \"--do_inference\",\n","                        default=False,\n","                        help=\"Whether to run inference with trained checkpoints\"\n","                        )\n","\n","    # other parameters\n","    parser.add_argument(\"--max_seq_length\", default=200, type=int)\n","    parser.add_argument(\"--n_gpu\", default=0)\n","    parser.add_argument(\"--train_batch_size\",\n","                        default=16,\n","                        type=int,\n","                        help=\"Batch size per GPU/CPU for training.\"\n","                        )\n","    parser.add_argument(\"--eval_batch_size\",\n","                        default=64,\n","                        type=int,\n","                        help=\"Batch size per GPU/CPU for evaluation.\"\n","                        )\n","    parser.add_argument(\n","                        '--gradient_accumulation_steps',\n","                        type=int,\n","                        default=1,\n","                        help=\n","                        \"Number of updates steps to accumulate before performing a backward/update pass.\"\n","                        )\n","    parser.add_argument(\"--learning_rate\", default=1e-4, type=float)\n","    parser.add_argument(\"--num_train_epochs\",\n","                        default=20,\n","                        type=int,\n","                        help=\"Total number of training epochs to perform.\"\n","                        )\n","    parser.add_argument('--seed',\n","                        type=int,\n","                        default=25,\n","                        help=\"random seed for initialization\"\n","                        )\n","\n","    # training details\n","    parser.add_argument(\"--weight_decay\", default=0.0, type=float)\n","    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float)\n","    parser.add_argument(\"--warmup_steps\", default=0.0, type=float)\n","    parser.add_argument(\"--top_k\", default=1, type=int)\n","    parser.add_argument(\"--multi_path\", action='store_true')\n","    parser.add_argument(\"--num_path\", default=1, type=int)\n","    parser.add_argument(\"--beam_size\", default=1, type=int)\n","    parser.add_argument(\"--save_top_k\", default=1, type=int)\n","    parser.add_argument(\"--check_val_every_n_epoch\", default=1, type=int)\n","    parser.add_argument(\"--single_view_type\",\n","                    default=\"rank\",\n","                    choices=[\"rank\", \"rand\", \"heuristic\"],\n","                    type=str)\n","    parser.add_argument(\"--ctrl_token\",\n","                        default=\"post\",\n","                        choices=[\"post\", \"pre\", \"none\"],\n","                        type=str)\n","    parser.add_argument(\"--sort_label\",\n","                        action='store_true',\n","                        help=\"sort tuple by order of appearance\")\n","    parser.add_argument(\"--load_path_cache\",\n","                        action='store_true',\n","                        help=\"load decoded path from cache\")\n","    parser.add_argument(\"--lowercase\", action='store_true')\n","    parser.add_argument(\"--multi_task\", action='store_true')\n","    parser.add_argument(\"--constrained_decode\",\n","                        action=\"store_true\",\n","                        help='constrained decoding when evaluating')\n","    parser.add_argument('--agg_strategy', type=str, default='vote', choices=['vote', 'rand', 'heuristic', 'pre_rank', 'post_rank'])\n","    parser.add_argument(\"--data_ratio\",\n","                        default=1.0,\n","                        type=float,\n","                        help=\"low resource data ratio\")\n","\n","    # args = parser.parse_args()\n","    args, unknown = parser.parse_known_args()\n","\n","    # set up output dir which looks like './outputs/rest15/'\n","    if not os.path.exists('./outputs'):\n","        os.mkdir('./outputs')\n","\n","    if not os.path.exists(args.output_dir):\n","        os.mkdir(args.output_dir)\n","\n","    return args"]},{"cell_type":"markdown","metadata":{"id":"ePwWBg4M1jcO"},"source":["## T5 fine tuner"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njpwo-BMqGMV"},"outputs":[],"source":["class T5FineTuner(pl.LightningModule):\n","    \"\"\"\n","    Fine tune a pre-trained T5 model\n","    \"\"\"\n","\n","    def __init__(self, config, tfm_model, tokenizer):\n","        super().__init__()\n","        self.save_hyperparameters(ignore=['tfm_model'])\n","        self.config = config\n","        self.model = tfm_model\n","        self.tokenizer = tokenizer\n","\n","    def forward(self,\n","                input_ids,\n","                attention_mask=None,\n","                decoder_input_ids=None,\n","                decoder_attention_mask=None,\n","                labels=None):\n","        return self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            labels=labels,\n","        )\n","\n","    def _step(self, batch):\n","        lm_labels = batch[\"target_ids\"]\n","        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(input_ids=batch[\"source_ids\"],\n","                       attention_mask=batch[\"source_mask\"],\n","                       labels=lm_labels,\n","                       decoder_attention_mask=batch['target_mask'])\n","\n","        loss = outputs[0]\n","        return loss\n","\n","    def training_step(self, batch, batch_idx):\n","        loss = self._step(batch)\n","        self.log(\"train_loss\", loss)\n","        return loss\n","\n","    def evaluate(self, batch, stage=None):\n","        # get f1\n","        outs = self.model.generate(input_ids=batch['source_ids'],\n","                                   attention_mask=batch['source_mask'],\n","                                   max_length=self.config.max_seq_length,\n","                                   return_dict_in_generate=True,\n","                                   output_scores=True,\n","                                   num_beams=1)\n","\n","        dec = [\n","            self.tokenizer.decode(ids, skip_special_tokens=True)\n","            for ids in outs.sequences\n","        ]\n","        target = [\n","            self.tokenizer.decode(ids, skip_special_tokens=True)\n","            for ids in batch[\"target_ids\"]\n","        ]\n","        scores, _, _ = compute_scores(dec, target, verbose=False)\n","        f1 = torch.tensor(scores['f1'], dtype=torch.float64)\n","\n","        # get loss\n","        loss = self._step(batch)\n","\n","        if stage:\n","            self.log(f\"{stage}_loss\",\n","                     loss,\n","                     prog_bar=True,\n","                     on_step=False,\n","                     on_epoch=True)\n","            self.log(f\"{stage}_f1\",\n","                     f1,\n","                     prog_bar=True,\n","                     on_step=False,\n","                     on_epoch=True)\n","\n","    def validation_step(self, batch, batch_idx):\n","        self.evaluate(batch, \"val\")\n","\n","    def test_step(self, batch, batch_idx):\n","        self.evaluate(batch, \"test\")\n","\n","    def configure_optimizers(self):\n","        \"\"\" Prepare optimizer and schedule (linear warmup and decay) \"\"\"\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [\n","                    p for n, p in model.named_parameters()\n","                    if not any(nd in n for nd in no_decay)\n","                ],\n","                \"weight_decay\":\n","                self.config.weight_decay,\n","            },\n","            {\n","                \"params\": [\n","                    p for n, p in model.named_parameters()\n","                    if any(nd in n for nd in no_decay)\n","                ],\n","                \"weight_decay\":\n","                0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                          lr=self.config.learning_rate,\n","                          eps=self.config.adam_epsilon)\n","        scheduler = {\n","            \"scheduler\":\n","            get_linear_schedule_with_warmup(optimizer,\n","                                            **self.config.lr_scheduler_init),\n","            \"interval\":\n","            \"step\",\n","        }\n","        return [optimizer], [scheduler]\n","\n","    def train_dataloader(self):\n","        print(\"load training data.\")\n","        train_dataset = ABSADataset(tokenizer=self.tokenizer,\n","                                    task_name=args.task,\n","                                    data_name=args.dataset,\n","                                    data_type=\"train\",\n","                                    top_k=self.config.top_k,\n","                                    args=self.config,\n","                                    max_len=self.config.max_seq_length)\n","\n","        dataloader = DataLoader(\n","            train_dataset,\n","            batch_size=self.config.train_batch_size,\n","            drop_last=True\n","            if args.data_ratio > 0.3 else False, # don't drop on few-shot\n","            shuffle=True,\n","            num_workers=2)\n","\n","        return dataloader\n","\n","    def val_dataloader(self):\n","        val_dataset = ABSADataset(tokenizer=self.tokenizer,\n","                                  task_name=args.task,\n","                                  data_name=args.dataset,\n","                                  data_type=\"dev\",\n","                                  top_k=self.config.num_path,\n","                                  args=self.config,\n","                                  max_len=self.config.max_seq_length)\n","        return DataLoader(val_dataset,\n","                          batch_size=self.config.eval_batch_size,\n","                          num_workers=2)\n","\n","    @staticmethod\n","    def rindex(_list, _value):\n","        return len(_list) - _list[::-1].index(_value) - 1\n","\n","    def prefix_allowed_tokens_fn(self, task, data_name, source_ids, batch_id,\n","                                 input_ids):\n","        \"\"\"\n","        Constrained Decoding\n","        # ids = self.tokenizer(\"text\", return_tensors='pt')['input_ids'].tolist()[0]\n","        \"\"\"\n","        if not os.path.exists('./force_tokens.json'):\n","            dic = {\"cate_tokens\":{}, \"all_tokens\":{}, \"sentiment_tokens\":[], 'special_tokens':[]}\n","            for task in force_words.keys():\n","                dic[\"all_tokens\"][task] = {}\n","                for dataset in force_words[task].keys():\n","                    cur_list = force_words[task][dataset]\n","                    tokenize_res = []\n","                    for w in cur_list:\n","                        tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0])\n","                    dic[\"all_tokens\"][task][dataset] = tokenize_res\n","            for k,v in cate_list.items():\n","                tokenize_res = []\n","                for w in v:\n","                    tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0])\n","                dic[\"cate_tokens\"][k] = tokenize_res\n","            sp_tokenize_res = []\n","            for sp in ['great', 'ok', 'bad']:\n","                sp_tokenize_res.extend(self.tokenizer(sp, return_tensors='pt')['input_ids'].tolist()[0])\n","            for task in force_words.keys():\n","                dic['sentiment_tokens'][task] = sp_tokenize_res\n","            dic['sentiment_tokens'] = sp_tokenize_res\n","            special_tokens_tokenize_res = []\n","            for w in ['[O','[A','[S','[C','[SS']:\n","                special_tokens_tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0])\n","            special_tokens_tokenize_res = [r for r in special_tokens_tokenize_res if r != 784]\n","            dic['special_tokens'] = special_tokens_tokenize_res\n","            import json\n","            with open(\"force_tokens.json\", 'w') as f:\n","                json.dump(dic, f, indent=4)\n","\n","        to_id = {\n","            'OT': [667],\n","            'AT': [188],\n","            'SP': [134],\n","            'AC': [254],\n","            'SS': [4256],\n","            'EP': [8569],\n","            '[': [784],\n","            ']': [908],\n","            'it': [34],\n","            'null': [206,195]\n","        }\n","\n","        left_brace_index = (input_ids == to_id['['][0]).nonzero()\n","        right_brace_index = (input_ids == to_id[']'][0]).nonzero()\n","        num_left_brace = len(left_brace_index)\n","        num_right_brace = len(right_brace_index)\n","        last_right_brace_pos = right_brace_index[-1][\n","            0] if right_brace_index.nelement() > 0 else -1\n","        last_left_brace_pos = left_brace_index[-1][\n","            0] if left_brace_index.nelement() > 0 else -1\n","        cur_id = input_ids[-1]\n","\n","        if cur_id in to_id['[']:\n","            return force_tokens['special_tokens']\n","        elif cur_id in to_id['AT'] + to_id['OT'] + to_id['EP'] + to_id['SP'] + to_id['AC']:\n","            return to_id[']']\n","        elif cur_id in to_id['SS']:\n","            return to_id['EP']\n","\n","        # get cur_term\n","        if last_left_brace_pos == -1:\n","            return to_id['['] + [1]   # start of sentence: [\n","        elif (last_left_brace_pos != -1 and last_right_brace_pos == -1) \\\n","            or last_left_brace_pos > last_right_brace_pos:\n","            return to_id[']']  # ]\n","        else:\n","            cur_term = input_ids[last_left_brace_pos + 1]\n","\n","        ret = []\n","        if cur_term in to_id['SP']:  # SP\n","            ret = force_tokens['sentiment_tokens'][task]\n","        elif cur_term in to_id['AT']:  # AT\n","            force_list = source_ids[batch_id].tolist()\n","            if task != 'aste':\n","                force_list.extend(to_id['it'] + [1])\n","            ret = force_list\n","        elif cur_term in to_id['SS']:\n","            ret = [3] + to_id[']'] + [1]\n","        elif cur_term in to_id['AC']:  # AC\n","            ret = force_tokens['cate_tokens'][data_name]\n","        elif cur_term in to_id['OT']:  # OT\n","            force_list = source_ids[batch_id].tolist()\n","            if task == \"acos\":\n","                force_list.extend(to_id['null'])  # null\n","            ret = force_list\n","        else:\n","            raise ValueError(cur_term)\n","\n","        if num_left_brace == num_right_brace:\n","            ret = set(ret)\n","            ret.discard(to_id[']'][0]) # remove ]\n","            for w in force_tokens['special_tokens']:\n","                ret.discard(w)\n","            ret = list(ret)\n","        elif num_left_brace > num_right_brace:\n","            ret += to_id[']']\n","        else:\n","            raise ValueError\n","        ret.extend(to_id['['] + [1]) # add [\n","        return ret"]},{"cell_type":"markdown","metadata":{"id":"TUSernYO1pxd"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOgD9qe3qMPU"},"outputs":[],"source":["def evaluate(model, task, data, data_type):\n","    \"\"\"\n","    Compute scores given the predictions and gold labels\n","    \"\"\"\n","    tasks, datas, sents, _ = read_line_examples_from_file(\n","        f'../data/{task}/{data}/{data_type}.txt', task, data, lowercase=False)\n","\n","    outputs, targets, probs = [], [], []\n","    num_path = args.num_path\n","    if task in ['aste', 'tasd']:\n","        num_path = min(5, num_path)\n","\n","    cache_file = os.path.join(\n","        args.output_dir, \"result_{}{}{}_{}_path{}_beam{}.pickle\".format(\n","            \"best_\" if args.load_ckpt_name else \"\",\n","            \"cd_\" if args.constrained_decode else \"\", task, data, num_path,\n","            args.beam_size))\n","    if args.load_path_cache:\n","        with open(cache_file, 'rb') as handle:\n","            (outputs, targets, probs) = pickle.load(handle)\n","    else:\n","        dataset = ABSADataset(model.tokenizer,\n","                              task_name=task,\n","                              data_name=data,\n","                              data_type=data_type,\n","                              top_k=num_path,\n","                              args=args,\n","                              max_len=args.max_seq_length)\n","        data_loader = DataLoader(dataset,\n","                                 batch_size=args.eval_batch_size,\n","                                 num_workers=2)\n","        device = torch.device('cuda:0')\n","        model.model.to(device)\n","        model.model.eval()\n","\n","        for batch in tqdm(data_loader):\n","            # beam search\n","            outs = model.model.generate(\n","                input_ids=batch['source_ids'].to(device),\n","                attention_mask=batch['source_mask'].to(device),\n","                max_length=args.max_seq_length,\n","                num_beams=args.beam_size,\n","                early_stopping=True,\n","                return_dict_in_generate=True,\n","                output_scores=True,\n","                prefix_allowed_tokens_fn=partial(\n","                    model.prefix_allowed_tokens_fn, task, data,\n","                    batch['source_ids']) if args.constrained_decode else None,\n","            )\n","\n","            dec = [\n","                model.tokenizer.decode(ids, skip_special_tokens=True)\n","                for ids in outs.sequences\n","            ]\n","            target = [\n","                model.tokenizer.decode(ids, skip_special_tokens=True)\n","                for ids in batch[\"target_ids\"]\n","            ]\n","            outputs.extend(dec)\n","            targets.extend(target)\n","\n","        # save outputs and targets\n","        with open(cache_file, 'wb') as handle:\n","            pickle.dump((outputs, targets, probs), handle)\n","\n","    if args.multi_path:\n","        targets = targets[::num_path]\n","\n","        # get outputs\n","        _outputs = outputs # backup\n","        outputs = [] # new outputs\n","        if args.agg_strategy == 'post_rank':\n","            inputs = [ele for ele in sents for _ in range(num_path)]\n","            assert len(_outputs) == len(inputs), (len(_outputs), len(inputs))\n","            preds = [[o] for o in _outputs]\n","            model_path = os.path.join(args.output_dir, \"final\")\n","            scores = cal_entropy(inputs, preds, model_path, model.tokenizer)\n","\n","        for i in range(0, len(targets)):\n","            o_idx = i * num_path\n","            multi_outputs = _outputs[o_idx:o_idx + num_path]\n","\n","            if args.agg_strategy == 'post_rank':\n","                multi_probs = scores[o_idx:o_idx + args.num_path]\n","                assert len(multi_outputs) == len(multi_probs)\n","\n","                sorted_outputs = [i for _,i in sorted(zip(multi_probs,multi_outputs))]\n","                outputs.append(sorted_outputs[0])\n","                continue\n","            elif args.agg_strategy == \"pre_rank\":\n","                outputs.append(multi_outputs[0])\n","                continue\n","            elif args.agg_strategy == 'rand':\n","                outputs.append(random.choice(multi_outputs))\n","                continue\n","            elif args.agg_strategy == 'heuristic':\n","                # aspect term > opinion term = aspect category > sentiment polarity\n","                optim_orders_all = get_orders_all()\n","                heuristic_orders =  get_orders_heuristic()\n","                index = optim_orders_all[task][data].index(heuristic_orders[task][0])\n","                outputs.append(multi_outputs[index])\n","                # at, ot/ac, sp\n","                continue\n","            elif args.agg_strategy == 'vote':\n","                all_quads = []\n","                for s in multi_outputs:\n","                    all_quads.extend(\n","                        extract_spans_para(seq=s, seq_type='pred'))\n","\n","                output_quads = []\n","                counter = dict(Counter(all_quads))\n","                for quad, count in counter.items():\n","                    # keep freq >= num_path / 2\n","                    if count >= len(multi_outputs) / 2:\n","                        output_quads.append(quad)\n","\n","                # recover output\n","                output = []\n","                for q in output_quads:\n","                    ac, at, sp, ot = q\n","                    if tasks[i] == \"aste\":\n","                        if 'null' not in [at, ot, sp]:  # aste has no 'null', for zero-shot only\n","                            output.append(f'[A] {at} [O] {ot} [S] {sp}')\n","\n","                    elif tasks[i] == \"tasd\":\n","                        output.append(f\"[A] {at} [S] {sp} [C] {ac}\")\n","\n","                    elif tasks[i] in [\"asqp\", \"acos\"]:\n","                        output.append(f\"[A] {at} [O] {ot} [S] {sp} [C] {ac}\")\n","\n","                    else:\n","                        raise NotImplementedError\n","\n","                target_quads = extract_spans_para(seq=targets[i],\n","                                                seq_type='gold')\n","\n","                if sorted(target_quads) != sorted(output_quads):\n","                    print(\"task, data:\", tasks[i], datas[i])\n","                    print(\"target:\", sorted(target_quads))\n","                    print('output:', sorted(output))\n","                    print(\"sent:\", sents[i])\n","                    print(\"counter:\", counter)\n","                    print(\"output quads:\", output)\n","                    print(\"multi_path:\", multi_outputs)\n","                    print()\n","\n","                # if no output, use the first path\n","                output_str = \" [SSEP] \".join(\n","                    output) if output else multi_outputs[0]\n","\n","                outputs.append(output_str)\n","\n","    # stats\n","    labels_counts = Counter([len(l.split('[SSEP]')) for l in outputs])\n","    print(\"pred labels count\", labels_counts)\n","\n","    scores, all_labels, all_preds = compute_scores(outputs,\n","                                                   targets,\n","                                                   verbose=True)\n","    return scores"]},{"cell_type":"markdown","metadata":{"id":"-aYssSdj1scz"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lz7AuJPEqOrG"},"outputs":[],"source":["def train_function(args):\n","\n","    # training process\n","    if args.do_train:\n","        print(\"\\n\", \"=\" * 30, f\"NEW EXP: {args.task} on {args.dataset}\",\n","              \"=\" * 30, \"\\n\")\n","        tokenizer = T5Tokenizer.from_pretrained(args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n","\n","        # sanity check\n","        # show one sample to check the code and the expected output\n","        print(f\"Here is an example (from the dev set):\")\n","        dataset = ABSADataset(tokenizer=tokenizer,\n","                              task_name=args.task,\n","                              data_name=args.dataset,\n","                              data_type='train',\n","                              top_k=args.top_k,\n","                              args=args,\n","                              max_len=args.max_seq_length)\n","        for i in range(0, min(10, len(dataset))):\n","            data_sample = dataset[i]\n","            print(\n","                'Input :',\n","                tokenizer.decode(data_sample['source_ids'],\n","                                 skip_special_tokens=True))\n","            print('Input :',\n","                  tokenizer.convert_ids_to_tokens(data_sample['source_ids']))\n","            print(\n","                'Output:',\n","                tokenizer.decode(data_sample['target_ids'],\n","                                 skip_special_tokens=True))\n","            print()\n","\n","        print(\"\\n****** Conduct Training ******\")\n","\n","        # initialize the T5 model\n","        tfm_model = MyT5ForConditionalGeneration.from_pretrained(\n","            args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n","        model = T5FineTuner(args, tfm_model, tokenizer)\n","\n","        # load data\n","        train_loader = model.train_dataloader()\n","\n","        # config optimizer\n","        t_total = ((len(train_loader.dataset) //\n","                    (args.train_batch_size * max(1, args.n_gpu))) //\n","                   args.gradient_accumulation_steps *\n","                   float(args.num_train_epochs))\n","\n","        args.lr_scheduler_init = {\n","            \"num_warmup_steps\": args.warmup_steps,\n","            \"num_training_steps\": t_total\n","        }\n","\n","        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","            dirpath=args.output_dir,\n","            filename='{epoch}-{val_f1:.2f}-{val_loss:.2f}',\n","            monitor='val_f1',\n","            mode='max',\n","            save_top_k=args.save_top_k,\n","            save_last=False)\n","\n","        early_stop_callback = EarlyStopping(monitor=\"val_f1\",\n","                                            min_delta=0.00,\n","                                            patience=20,\n","                                            verbose=True,\n","                                            mode=\"max\")\n","        lr_monitor = LearningRateMonitor(logging_interval='step')\n","\n","        # prepare for trainer\n","        train_params = dict(\n","            accelerator=\"gpu\",\n","            devices=1,\n","            default_root_dir=args.output_dir,\n","            accumulate_grad_batches=args.gradient_accumulation_steps,\n","            gradient_clip_val=1.0,\n","            max_epochs=args.num_train_epochs,\n","            check_val_every_n_epoch=args.check_val_every_n_epoch,\n","            callbacks=[\n","                checkpoint_callback, early_stop_callback,\n","                TQDMProgressBar(refresh_rate=10), lr_monitor\n","            ],\n","        )\n","\n","        trainer = pl.Trainer(**train_params)\n","\n","        trainer.fit(model)\n","\n","        # save the final model\n","        model.model.save_pretrained(os.path.join(args.output_dir, \"final\"), safe_serialization=False)\n","        tokenizer.save_pretrained(os.path.join(args.output_dir, \"final\"), safe_serialization=False)\n","        print(\"Finish training and saving the model!\")\n","\n","    if args.do_inference:\n","        print(\"\\n****** Conduct inference on trained checkpoint ******\")\n","\n","        # initialize the T5 model from previous checkpoint\n","        print(f\"Load trained model from {args.output_dir}\")\n","        print(\n","            'Note that a pretrained model is required and `do_true` should be False'\n","        )\n","        # model_path = os.path.join(args.output_dir, \"final\")\n","        model_path = args.model_name_or_path  # for loading ckpt\n","\n","        tokenizer = T5Tokenizer.from_pretrained(model_path)\n","        tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n","        model = T5FineTuner(args, tfm_model, tokenizer)\n","\n","        if args.load_ckpt_name:\n","            ckpt_path = os.path.join(args.output_dir, args.load_ckpt_name)\n","            print(\"Loading ckpt:\", ckpt_path)\n","            checkpoint = torch.load(ckpt_path)\n","            model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","        log_file_path = os.path.join(args.output_dir, \"result.txt\")\n","\n","        # compute the performance scores\n","        with open(log_file_path, \"a+\") as f:\n","            config_str = f\"seed: {args.seed}, beam: {args.beam_size}, constrained: {args.constrained_decode}\\n\"\n","            print(config_str)\n","            f.write(config_str)\n","\n","            if args.multi_task:\n","                f1s = []\n","                for task in task_data_list:\n","                    for data in task_data_list[task]:\n","                        scores = evaluate(model, task, data, data_type=args.eval_data_split)\n","                        print(task, data, scores)\n","                        exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n","                            args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'],\n","                            scores['f1'])\n","                        f.write(f\"{task}: \\t{data}: \\t{exp_results}\\n\")\n","                        f.flush()\n","                        f1s.append(scores['f1'])\n","                f.write(f\"Average F1: \\t{sum(f1s) / len(f1s)}\\n\")\n","                f.flush()\n","            else:\n","                scores = evaluate(model,\n","                                  args.task,\n","                                  args.dataset,\n","                                data_type=args.eval_data_split)\n","\n","                exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n","                    args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'], scores['f1'])\n","                print(exp_results)\n","                f.write(exp_results + \"\\n\")\n","                f.flush()\n","    # return scores['f1']"]},{"cell_type":"markdown","metadata":{"id":"3UMvIg8b1zih"},"source":["# Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Q1UZxvb1VqD"},"outputs":[],"source":["args = init_args()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJqKzJc6MMIy"},"outputs":[],"source":["args.do_train = True\n","args.do_inference = False\n","args.load_ckpt_name = True"]},{"cell_type":"code","source":["args.task, args.dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXKlS-ViJrta","executionInfo":{"status":"ok","timestamp":1723564108639,"user_tz":-420,"elapsed":57,"user":{"displayName":"Phuong Dam","userId":"01072403895711103873"}},"outputId":"43acf899-8440-4d60-87fd-f389b672ed27"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('asqp', 'gaming')"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["args.num_train_epochs = 2\n","args.eval_batch_size = 16"],"metadata":{"id":"PVAbLsDFJ0AY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIiTQ3jk1c0Q"},"outputs":[],"source":["train_function(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ot-6juL4DJwm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqIq2EP9qUhQ"},"outputs":[],"source":["# if __name__ == '__main__':\n","#     args = init_args()\n","#     set_seed(args.seed)\n","#     train_function(args)\n","\n","#     # auto run\n","#     args = init_args()\n","#     epoch_dict = {\n","#         0.01: 100,\n","#         0.02: 100,\n","#         0.05: 100,\n","#         0.1: 50,\n","#         0.2: 50,\n","#         1.0: 20,\n","#     }\n","#     epoch = epoch_dict[args.data_ratio]\n","#     args.num_train_epochs = epoch\n","#     print(\"Training epoch: \", epoch)\n","\n","#     f1_res = []\n","#     seed_list = [5, 10, 15, 20, 25]\n","#     for each_seed in seed_list:\n","#         args.seed = each_seed\n","#         set_seed(args.seed)\n","#         res = train_function(args)\n","#         f1_res.append(res)\n","\n","#     f1_str = \"F1 all seeds: {}, avg: {:.2f}\\n\".format(f1_res, sum(f1_res) / len(f1_res))\n","#     log_file_path = os.path.join(args.output_dir, \"result.txt\")\n","#     with open(log_file_path, \"a+\") as f:\n","#         f.write(f1_str)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvGf5RZo10PV"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}